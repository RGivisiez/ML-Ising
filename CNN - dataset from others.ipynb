{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle,os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import sys, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.figsize'] = [6.32, 5.11]\n",
    "#plt.rcParams['figure.constrained_layout.use'] = True\n",
    "\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['axes.linewidth'] = 3\n",
    "plt.rcParams['axes.labelpad'] = 15\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['xtick.major.size'] = 8\n",
    "plt.rcParams['xtick.major.width'] = 3\n",
    "\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['ytick.major.size'] = 8\n",
    "plt.rcParams['ytick.major.width'] = 3\n",
    "\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['legend.markerscale'] = 1\n",
    "\n",
    "plt.rcParams['lines.markersize'] = 9\n",
    "plt.rcParams['lines.linewidth'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 40\n",
    "temp_val = np.arange(0.25, 4.0001, 0.25)\n",
    "temp_samples = 10000\n",
    "total_samples = temp_samples * temp_val.shape[0]\n",
    "test_size = 0.1\n",
    "val_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_tc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(path + 'Ising2DFM_reSample_L40_T=All.pkl','rb'))\n",
    "data = np.unpackbits(data).reshape(-1, L * L).astype(int)\n",
    "data[np.where(data==0)]=-1\n",
    "\n",
    "labels = pickle.load(open(path + 'Ising2DFM_reSample_L40_T=All_labels.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tc = np.where(temp_val <= 2.)[0][-1] * temp_samples\n",
    "last_tc = np.where(temp_val >= 3)[0][1] * temp_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_labels = np.hstack([np.repeat(temp, temp_samples) for temp in temp_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split_tc:\n",
    "    \n",
    "    X_ordered = data[:first_tc, :]\n",
    "    Y_ordered = np.column_stack((labels[:first_tc], temp_labels[:first_tc]))\n",
    "\n",
    "    X_critical = data[first_tc:last_tc, :]\n",
    "    Y_critical = np.column_stack((labels[first_tc:last_tc], temp_labels[first_tc:last_tc]))\n",
    "\n",
    "    X_disordered = data[last_tc:, :]\n",
    "    Y_disordered = np.column_stack((labels[last_tc:], temp_labels[last_tc:]))\n",
    "\n",
    "    X = np.concatenate((X_ordered, X_disordered))\n",
    "    Y = np.concatenate((Y_ordered, Y_disordered))\n",
    "    \n",
    "    del X_ordered, Y_ordered, X_disordered, Y_disordered, data, labels\n",
    "\n",
    "else:\n",
    "    \n",
    "    X = data\n",
    "    Y = np.column_stack((labels, temp_labels))\n",
    "    \n",
    "    del data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=val_size)\n",
    "\n",
    "del X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], L, L, 1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], L, L, 1))\n",
    "X_critical = np.reshape(X_critical, (X_critical.shape[0], L, L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(2, 2), activation='relu', input_shape=(L, L, 1), \n",
    "         data_format='channels_last'))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "#model.add(Conv2D(filters=128, kernel_size=(2, 2), activation='relu'))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "          \n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "          \n",
    "#model.add(Dropout(0.5))\n",
    "          \n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train[:, 0], validation_data=(X_val, Y_val[:, 0]) , batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "\n",
    "#model.add(Conv2D(filters=10, kernel_size=(5, 5), strides=(1, 1), padding='valid', activation='relu', input_shape=(L,L,1), \n",
    "#         data_format='channels_last'))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Conv2D(filters=20, kernel_size=(5, 5), activation='sigmoid'))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "          \n",
    "#model.add(Flatten())\n",
    "\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "          \n",
    "#model.add(Dropout(0.5))\n",
    "          \n",
    "#model.add(Dense(1, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
